context("Bayesian utilities")

# Create test fixture for Bayesian utils
create_test_survival_data_bayes <- function(n = 50, treatment_effect = 0.7) {
  # Generate a simple dataset with survival data
  set.seed(456)
  
  # Generate treatment assignment
  arm <- sample(c("control", "treatment"), n, replace = TRUE)
  
  # Generate survival times based on treatment
  observed_time <- numeric(n)
  for (i in 1:n) {
    if (arm[i] == "control") {
      observed_time[i] <- rweibull(1, shape = 1.2, scale = 12)
    } else {
      # Treatment effect as hazard ratio
      observed_time[i] <- rweibull(1, shape = 1.2, scale = 12 / treatment_effect)
    }
  }
  
  # Generate event status (70% events)
  event_status <- rbinom(n, 1, 0.7)
  
  data <- data.frame(
    id = 1:n,
    arm = arm,
    observed_time = observed_time,
    event_status = event_status,
    stringsAsFactors = FALSE
  )
  
  return(data)
}

# Test create_hr_prior function
test_that("create_hr_prior creates valid hazard ratio priors", {
  # Normal prior
  normal_prior <- create_hr_prior(
    distribution = "normal",
    mean = 0,
    sd = 1
  )
  
  # Check structure
  expect_s3_class(normal_prior, "bayesian_prior")
  expect_equal(normal_prior$distribution, "normal")
  expect_equal(normal_prior$parameters$mean, 0)
  expect_equal(normal_prior$parameters$sd, 1)
  
  # Test student_t prior
  t_prior <- create_hr_prior(
    distribution = "student_t",
    mean = 0,
    sd = 1
  )
  
  expect_s3_class(t_prior, "bayesian_prior")
  expect_equal(t_prior$distribution, "student_t")
  expect_equal(t_prior$parameters$df, 3)  # Default df = 3
  
  # Test cauchy prior
  cauchy_prior <- create_hr_prior(
    distribution = "cauchy",
    mean = 0,
    sd = 2.5
  )
  
  expect_s3_class(cauchy_prior, "bayesian_prior")
  expect_equal(cauchy_prior$distribution, "cauchy")
  expect_equal(cauchy_prior$parameters$location, 0)
  expect_equal(cauchy_prior$parameters$scale, 2.5)
  
  # Test beta prior
  beta_prior <- create_hr_prior(
    distribution = "beta",
    alpha = 2,
    beta = 5
  )
  
  expect_s3_class(beta_prior, "bayesian_prior")
  expect_equal(beta_prior$distribution, "beta")
  expect_equal(beta_prior$parameters$alpha, 2)
  expect_equal(beta_prior$parameters$beta, 5)
  
  # Test gamma prior
  gamma_prior <- create_hr_prior(
    distribution = "gamma",
    alpha = 2,
    beta = 1
  )
  
  expect_s3_class(gamma_prior, "bayesian_prior")
  expect_equal(gamma_prior$distribution, "gamma")
  expect_equal(gamma_prior$parameters$shape, 2)
  expect_equal(gamma_prior$parameters$rate, 1)
  
  # Test informativeness flag
  strong_prior <- create_hr_prior(distribution = "normal", mean = 0.8, sd = 0.2)
  expect_true(strong_prior$is_informative)
  
  weak_prior <- create_hr_prior(distribution = "normal", mean = 0, sd = 20)
  expect_false(weak_prior$is_informative)
})

# Test update_prior function
test_that("update_prior correctly updates prior with new data", {
  # Skip test unless Bayesian packages are available
  skip_if_not_installed(c("brms", "rstanarm"))
  
  # Create a prior
  prior <- create_hr_prior(
    distribution = "normal",
    mean = 0,
    sd = 1
  )
  
  # Create test data
  data <- create_test_survival_data_bayes(n = 20)
  
  # Try to update prior
  tryCatch({
    # This may fail due to Stan/brms setup issues, which we'll skip
    posterior <- update_prior(prior, data)
    
    # Check structure
    expect_s3_class(posterior, "bayesian_posterior")
    expect_true(!is.null(posterior$model))
    expect_true(!is.null(posterior$samples))
    expect_true(!is.null(posterior$mean))
    expect_true(!is.null(posterior$median))
    expect_true(!is.null(posterior$sd))
    expect_true(!is.null(posterior$quantiles))
    expect_identical(posterior$prior, prior)
    
  }, error = function(e) {
    skip("Skipping Bayesian prior updating test due to model fitting issues")
  })
})

# Test calculate_effect_probability function
test_that("calculate_effect_probability computes correct probabilities", {
  # Create a mock posterior object
  mock_posterior <- list(
    samples = list(
      b_armtreatment = c(-0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4)
    )
  )
  class(mock_posterior) <- "bayesian_posterior"
  
  # Calculate probability of effect < 0 (any benefit)
  prob_any <- calculate_effect_probability(mock_posterior, threshold = 0)
  expect_equal(prob_any, 0.6)  # 6 out of 10 samples < 0
  
  # Calculate probability of effect < log(0.8) (meaningful benefit)
  prob_meaningful <- calculate_effect_probability(mock_posterior, threshold = log(0.8))
  expect_equal(prob_meaningful, 0.2)  # 2 out of 10 samples < log(0.8) â‰ˆ -0.22
})

# Test predict_survival function
test_that("predict_survival generates valid survival predictions", {
  # Skip test unless Bayesian packages are available
  skip_if_not_installed("brms")
  
  # Create mock posterior model and samples
  # This is a very simplified mock that doesn't rely on actual model fitting
  mock_posterior <- list(
    model = list(
      predict = function(newdata, type) {
        # Mock prediction function
        n <- nrow(newdata)
        times <- seq(0, 24, by = 0.5)
        matrix(runif(n * length(times), 0.5, 1), nrow = n)
      }
    ),
    samples = list(
      b_armtreatment = rnorm(100, -0.2, 0.1)
    )
  )
  class(mock_posterior) <- "bayesian_posterior"
  
  # Create newdata for predictions
  newdata <- data.frame(arm = c("control", "treatment"))
  
  # Generate predictions
  predictions <- predict_survival(mock_posterior, newdata)
  
  # Check structure
  expect_true(is.data.frame(predictions))
  expect_true("time" %in% names(predictions))
  expect_true("arm" %in% names(predictions))
  expect_true("survival" %in% names(predictions))
  
  # Predictions should be between 0 and 1
  expect_true(all(predictions$survival >= 0 & predictions$survival <= 1))
  
  # Each arm should have predictions at all time points
  expect_equal(sum(predictions$arm == "control"), sum(predictions$arm == "treatment"))
})

# Test adaptive_randomization function
test_that("adaptive_randomization creates allocation based on posterior", {
  # Create mock posterior
  mock_posterior <- list(
    samples = list(
      b_armtreatment = c(rep(-0.5, 80), rep(0.1, 20))  # 80% probability of benefit
    )
  )
  class(mock_posterior) <- "bayesian_posterior"
  
  # Run adaptive randomization
  randomization <- adaptive_randomization(mock_posterior, n_subjects = 50)
  
  # Check structure
  expect_true(is.list(randomization))
  expect_true(!is.null(randomization$arms))
  expect_true(!is.null(randomization$allocation))
  expect_true(!is.null(randomization$prob_better))
  
  # Check length
  expect_length(randomization$arms, 50)
  
  # Check allocation probabilities
  expect_equal(randomization$prob_better, 0.8)
  expect_true(randomization$allocation["treatment"] > 0.5)  # Treatment should get higher allocation
  
  # Check that min allocation is respected
  min_alloc <- 0.2
  randomization_min <- adaptive_randomization(mock_posterior, n_subjects = 100, min_allocation = min_alloc)
  expect_true(randomization_min$allocation["control"] >= min_alloc)
  expect_true(randomization_min$allocation["treatment"] >= min_alloc)
})